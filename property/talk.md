# Какие наши цели?
В чем состоит задача программиста? Один из самых популярных ответов - предоставлять некотрое решение существующей проблемы. Неотъемлемой частью предоставления решения является стадия анализа разработанного решения, в которой мы пытаемся понять, что за решение мы получили, какие у него ограничения, область применения, на какие компромисы оно идет - на сколько хорошо оно решает изначальную проблему и сколько других проблем добавляет.

И сейчас зачастую эта стадия существует при разработке ПО, однако она протекает по большей части неосознанно в процессе непосредественно проектирования, программирования, тестирования.
Помимо того что она стадия анализа во многом протекает неявно и неосознано она зачастую происходит в неформальных терминах.
"Это ненадежное решение", "Это плохо читаемый код", "Плохо тестируется" и так далее - это и многое другое зачастую очень долго обсуждается на код ревью и в процессе разработки.

Давайте попробуем понять откуда вообще появляется нужда в стадии анализа  разработанного решения и что должно являтся результатом этого анализа.
---
# Единственный источник истины
Что является главным и полным источником истины о коде?

Если размышлять до конца единственным полным и точным источником истины о коде будет являтся сам код.

Все остальное практически всегда будет лишь некотрой проекцией нашего кода - симукляром, либо не полным либо достаточно точным.

Почему тогда мы не можем просто анализировать код во время его написания и составлять тем самым полную картину того как он работает? 
ведь мы же пишем этот самый код - тогда почему нам вообще надо его как то анализировать?
разве мы не знаем что мы пишем?
---
# Но истина мимолетна
Давайте вернемся к тому зачем вообще пишется код.
Любая программа решает определенную проблему ВНЕШНЕГО мира.
То есть требования к тому как должен работать наш код - в соответствии с которым мы пишем наш код - берутся не из воздуха а из какой то реальной необходимости.

Каим главным свойством обладает реальный мир который диктует требования к нашему коду? Переменчивость - внешний мир постоянно развивается и соотвественно развиваются и требования к коду.

Все это ведет к тому что и сам код постоянно находится в процессе развития - это не застывший камень а постоянно развивающийся организм.

Очевидно что любые перемены всегда несут некотрую опастность - а что если мы изменим наш код не верно?
Что если наше изменение сломает чтото из уже готового функционала, или наоборот - какой то старый функционал не даст нам реализовать верно новые требования.

К примеру на слайде мы видим пример довольно простого изменения кода - можем ли мы сказать меняет ли это изменение поведение кода или нет? Можем ли мы сказать хоть чтото? по этому изменению?
Нет - если мы хотим заново выяснить чтоже делает наш код - нам придется разобратся снова с ним со всем и заново проанализировать все исходники - а не только тот участок который непосредственно изменился.

И здесь мы сталкиваемся со второй особенностью свойственной почти любой системе - "целое всегда больше суммы частей".

Если мы знаем как работает код в момент перед изменением, и видим само изменение то мы не можем корректно предсказать как это изменение скажется на работе системы, практически всегда невозможно просто сложить знание о результате работы кода до правки и том как работает само исправление.
Просто потому что любая сущность в программе не висит в воздухе а связана с остальными множеством связей причем не всегда явных.

В итоге получается что изменения страшный враг программиста и нам нужно старатся боротся с ними или их избегать?
---
# Не борьба, а наблюдение
Однако очевидно что любая борьба с изменениями просто не возможна. Ведь в них и содержится вся та полезность от ПО ради которой все затевается.

Практически всегда лучшей тактикой будет, не пытатся избежать изменений, а сделать их явными и наблюдаемыми

На самом деле мы уже используем эту технику для отслеживания изменений в нашем коде.
Вместо того чтобы просто произвольно править файл и перезатирая его состояние мы используем гит и другие системы контроля версий, как раз таки для того чтобы изменения нашего кода были отслеживаемы и наблюдаемы.

Однако как мы уже выясняли отслеживаемость изменений сама по себе не помогает нам понять насколько эти изменения соотвествуют или не соответствуют нашим ожиданиям. Почему так происходит?

Давайте попробуем понять что такое вообще "изменение" как термин - в отрыве от программирования.

Для меня было большим удивлением узнать что слово "изменение" происходит от слов "мена" и "обмен" в русском языке. А английское слово Change происходит от "exchange".

То есть и в русском и английском языке люди подметили что любое изменение это всегда двусторонний процесс - еще до того как физики открыли второй закон термодинамики люди видили что наш мир пронизывает множество связей и нельзя изменить чтото одно - этим самым мы всегда изменяем еще чтото. можно сказать что обмениваем изменение одной сущности или признака на изменение другой сузности или признака.

Так на что мы обмениваем изменение кода(представленное патчом в вкс)?

мы обмениваем его на изменение в поведении работы нашей программы
Каждый патч в вкс, каждая измененая строчка кода ведет к изменениям поведения нашей программы. И вот они то и ускальзают от нашего взгляда - ниодна система контроля версий к сожалению никогда не скажет нам как изменилось поведение нашего кода в результате каждой конкретной правки.

И собственно отсуствие возможности наблюдать изменения поведения нашей программы явно заставляет нас совершать стадию анализа - результатом которой должно стать автоматизированное доказательство определенного поведения нашей программмы - тогда любые изменения в поведении кода станут наблюдаемыми - если поведение изменится то наше доказтельство нам скажет об этом.

Но прежде чем перейти к практике - к доказательствам. Давайте попробуем разобратся а какое вообще бывает поведение? и какие бывают соотвественно его виды
---
# Что такое хорошо и что такое плохо?
когда мы говорим о поведении мы обычно говорим об отдельных его аспектах.
К примеру сумма 2 и 2 возвращает 4 - мы можем сказать это поведение верное - оно соответсвует постановке. Давайте называть такое поведение - желательным.

Однако сумма 2 и 2 может в другой реализации вернуть нам к примеру строку - это поведение не соответсвует исходной постановке оно неверно и соответсвенно мы назовем его нежелательным.
То есть глобально существует два вида поведения.

Соотвественно и классификация доказательств также распадается на два направления согласно тому какой из видов поведения мы хотим доказать

 - доказательства отсуствия некотрого нежелательного поведения - свойство безопастности системы(safety) - то есть доказываем что наша программа не стирает хард не сжигает процессор и не убивает котят
 - доказательства наличия некотрого желательного поведения - свойство живости системы(liveness) - то есть доказываем что наша система работает верно и допустим всетаки реально складывает два числа.

 что интересно эти свойства как вы могли заметить взаимозаменяемы - полное отсутвие нежелательного поведения говорит о том что наша программа всегда ведет себя так как мы то нее этого ожидаем - то есть если мы сможем доказать полностью чтото одно то другое будет также доказано
 Однако проблема в то что доказать полностью ни то ни другое практически невозможно. Поэтому обычно используются комбинации доказательств
---
# Программа работает верно
вспомним простейший способ доказать желательное поведение программы - это банальные тесты.

в тестах мы закрепляем поведение нашего в отдельных тест кейзах.

Давайте попробуем поразмышлять сколько тестов нам надо написать
Сколько тестов будет достаточно чтобы доказать корректность?
---
# Но это не точно...

Тестирования не достаточно
Программа - это функция
Тест - это проверка функции в конкретной точке
Множество точек на которых определена программа обычно **близко к бесконечному**
---
# Математики vs программисты

Сравниваем подходы к проблемы математиков и программистов
---
# Пусть хотя бы ничего не ломает
Окей даваайте тогда еще начнем отсекать нежелательное поведение
например

---
# Есть два способа...
Сложный -  статически при помощи Coq/Agda/TLA+/Lean Prover
Простой проверить это свойство на очень многих случайных точках
давайте проверим свойство суммы что сумма двух положительных чисел положительна
---
# Property-based testing

Шаги:
 - описываем свойство
 - генерим много различных вариантов аргументов
 - проверяем что на всех аргументах свойство соблюдается

Библиотеки:
 - testcheck.js (порт clojure core.check)
 - jsverify
---
# Перерыв 1
---
# Вернемся к реальной жизни
типичная ситуация - получили данные с бекенда конвертнули в вид удобный для представления а затем конвертнули обратно - в вид необходимый для апи
---
# Как создать семью?
описываю как создаются генераторы и что их можно комбайнить
генераторы похожи на описание propTypes
---
# Запрет на многоженство - динамические ограничения
динамические ограничения которые не укладываются в рамки готовых генератов делаем при помощи smap - отображаем генерируемые элементы при помощи некой функции
---
# Умолчания
Вот же засада - оказывается наши функции не обладают нужным свойством
функция convertFrom, помимо преобразований из одной структуры в другую, также проставляет некоторые значения по умолчанию (для dependant это false), то есть она не оставляет исходные значения.
мы можем ослабить свойство и проверять не на точное равенство, а на то, что структура не изменяется

---
# Изменим проверку
давайте используем для этого библиотеку рантайпс
альтернативы - ткомб, ио-тс итд можно даже проп-тайпс
согласитесь описание структуры очень похоже на описание генератора?
может мы можем получить одно из другого
---
# Легким движением руки валидатор преврашается...В генератор!
да можем - показываю как генерится генератор из валидатора
говорю что при помощи такого подхода можно проверять свойства просто описывая аргументы функций и компонентов - то есть можно например проверить prop-types на CI
---
# Перерыв 2
---
# Что-то это все напоминает...
Люди которые пишут на тайпскрипт могли заметить что описание генератора и валидатора очень похоже на описание статических типов

а само свойство можно записать как описание типов функции
---
# Лирическое отступление: что такое статические типы
Аннотации типов не просто *часть* языка - это *отдельный* язык.
---
# Пример: натуральные числа
например мы довольно просто можем закодировать числа при помощи системы типов
Note: данный "прием" называется [числа Черча]
---
# Но есть небольшая проблема...
а затем при помощи этих натуральных чисел сделать тип вектор - массив ограниченой длины статически
И вот какую ошибку мы увидим в случае если компилятор не увидит доказательств правильности работы нашего кода
---
# Альтернатива?
И натуральное число и вектор все это пример зависимых типов

*Типы ограниченные до значений* - то есть позволяют связать с типом некотрое значение в нашем коде и тем самым полностью доказывать работу программы
Пример суммы с зависимыми типами

Зависимые типы и есть теорем прувинг которого мы так боялись

Более человеческой альтернативой зависимым типам будет являтся рефайнемент типы 
пример типа натуральное число - посути ппозволяют записывать произвольные свойства в типах  и проверять их статически

но пока не существуют
---
# Перерыв 3
---
# Статика против динамики
Окей теперь мы с вами знакомы со всем многообразием доказательств поведения программ
 тесты, проперти тесты(динамика), типы, теорем прувинг(статика)
 - давайте столкнем их лбами

среднее списка
Доказательство что эта функция для любого списка чисел вернет число.

говорю о разнице динамического и статического доказательства - статическое по построению диннамическое по результатам

---
# Proof Cube
все известные нам виды доказательств тем самым можно уложить в такой вот куб
---
# Пример
вот примеры этих доказательств на кубе
---
# Стеклянная стена между мирами
Статические(*по построению*):
обычно быстры
нужно постоянно доказывать компилятору что код не говно(по дефолту код считается негодным)
сложность зависит от узости типа - чем лучше тип ограничвает область желательных значений тем сложнее построить такой тип

Динамические(*по результатам*):
изза того что требуют запуска обычно работают долго
по дефолту считает что код ок и только если чтото где то зафейлится то код считается негодным
вероятностны и чем больше вероятность доказательства тем сложнее его написать
---
# Перерыв
---
# Вспомним пример

вспоминаем пример показываю что определения весьма похожи но между ними пропасть в виде компиляции - мы не можем переиспользовать типы определеные динамически статически и наоборот

если мы хотим и динамической проверки и статической(например для валидации данных из внешнего мира) - то надо писать два раза и нельзя перейти от одной к другой бесплатно
---
# Разбиваем стену

Однако библиотеки типа runtypes, io-ts которые позволяют получать из динамического описания статический эквивалент бесплатно

То есть один раз описав валидатор в виде динамического значения мы получаем:
 - динамический валидатор для данных из внешнего(нетипизированного) мира и сложных проверок не выразимых статически(например проверки строк по регекспу итд)
 - генератор данных для проперти тестов
 - статический тип для проверки тайпчекером на этапе компиляции

извечный холивар статические типы или динамические уходит в небытие - теперь это просто вопрос тактики. Это даже не вопрос того что для одного проекта лучше подходит одно а для другого другое
это просто

У любого проекта бывают разные этапы. Например:
 - стадия прототипа когда код постоянно переписывается и внутреняя структура часто меняется
 - стадия поддержки - когда структура строго закреплена и не меняется
 Причем на самом деле на одном проекте эти стадии могут сменятся не раз - например новые разделы могут добавлятся в виде прототипов
---
# Пример(все совпадения случайны!)
Задача: новый модуль для вычисления среднего списка чисел

Используем TypeScript с флагом --allowJs
и пишем реализацию без каких либо типов в жс файле
---
# Шаг 1. Прототип
Модуль экспериментален- внутренняя структура будет постоянно менятся и мы не можем позволить себе типы

Поэтому определяем динамическое ограничение(оно будет даже более точным чем его статический эквивалент) и проверяем его при помоши проперти тестов
---
# Шаг 2. Стабильная структура
Внутреняя структура модуля стабилизировалась - мы хотим гарантировать что мы не только получаем осмысленный результат но и код пишем верным образом. То есть само построение не допускает некотрого подмножества неверных результатов со 100% вероятностью

аннотируем типами все промежуточные вычисления
и получаем полностью типизированный модуль+доп проверку того что среднее всегда больше минимального значения в массиве и меньше максимального

Если вдруг модуль опять переходит в стадию прототипа то переименовываем его в жс удаляем статические типы и остаемся с динамическими проверками
---
# Перерыв
Давайте подумаем что еще можно полезного придумать?
---
# Генерация тестов из рантайма

Вообще писать тесты очень грустно и лениво - а что если их не писать?
Во время ручного тестирования программы наши функции вызваются и мы можем проследить что приходит каждой функции на вход и что на выход

Сериализовав вызовы в массив мы сможем
а) проанализировать и убедится что наша функция всегда работает верно(если нет то исправить результаты)
б) если это так то сконвертить этот массив в исходный код тестов для определенного тестового фреймворка
---
# Генерация типов из рантайма

На самом деле описание типов данных в программе тоже не самое веселое занятие
но мы опять таки можем обратится к работе программы в рантайме - если мы можем получить массив вызовов то мы можем и понять с какими типами работает функция

И точно также сгенерировать описание типов для конкретной библиотеки(к примеру для рантайпс)
Что для этого необходимо
а) надо научится по некотрому обьекту получать его тип рекурсивно
б) необходимо научится научится мержить типы - то есть получив вызовы из одного типа и из другого надо уметь обьекдинить их в один общий тип

есть Automatic annotations для кложуры который умеет такое делать
---
# Идеальный bottom-up pipeline

Давайте сведем это все вместе и получим очень удобный способ разработки снизу вверх - удобный для стандартного способа разработки - от прототипа к стабильному решению

1) Написали код(прототип) - он может не учитывать все кейсы(краевые случаи к примеру)
2) Протестировали немного руками - получили список вызовов - при необходимости поправили и уточнили
3) конвертим это в тесты
---
# Идеальный bottom-up pipeline
4) Затем из того же списка сгенерировали спецификации типов - при необходимости правим и уточняем
5) Спецификации используем для написание простых проперти тестов для доказательства что спецификации реально всегда соблюдаются. Тут мы можем узнать о многих краевых случаях нашей программы - например вариант с пустым списком для среднего(если не учесть этот вариант скорее мы получим NaN)
6) Когда код стал стабильным - переключаемся на статический режим и добавляем недостающие статические типы
Если вдруг модуль снова перейдет в стадию активной переработки - убираем типы и возвращаемся к шагу 1
---
# Перерыв
Продолжаем генерить гениальные идеи
---
# Автоматическое доказательство корректности версионирования
Давайте всспомним о том что вообще порождает необходимость в доказательствах - изменения программы.
На текущих  момент существуют различные схемы версионирования изменений - самая известная это семвер - семантическое версионирование

Состоит из 3 цифр
1) мажорное изменение - обратно несовместимо
2) минорное изменение - обратно совместимо
3) исправление бага - обратно совместимый багфикс
Есть еще версия ComVer - где 2 и 3 выражаются в одной цифре

нетрудно заметить что ключевым здесь является понятие обратной совместимости - и именнно оно важно для польззователя модуля при обновлении с одной версии на другую. Важно понимать может ли обновление чтото изменить в вповедении программы

То есть возникает вопрос.
Как доказать что изменение обратно-совместимо?
---
# Автоматическое доказательство корректности версионирования
Как вы догадались есть 2 способа
Можно пойти от тестов - это динамический способ - используется в семантик-релиз Cracks
Он прогоняет тесты предыдущей версии на новой версии - если тесты не упали то изменение обратно совместимо

С другой стороны можно пойти от типов - это статический способ - используется
 в Elm-package. При обновлении версии ельм сравнивает сигнатуры функций старой версии модуля и новой - и если они не совпадают то говорит что измение обратно не совместимо
---
# Проблемы?
Но как всегда есть проблемы
давайте расмотрим пример со средним
Расмотрим один из самых лучших случаев - у нас есть и тесты(даже с краевыми случаями) и типы

Теперь давайте изменим реализацию среднего на медиану(значение из списка которое больше 50 процентов значений) - изменение пройдет незамеченным. Типы остались теже а тесты не учитывают всех кейсов
---
# Решение - синтез подходов
1) Возьмем динамическое описание типа функции - старое и новое

2) Проверяем что сами спецификации не изменились("статический" подход) - для этого нам надо уметь сравнивать спеки с учетом эквивалентности типов и того что одни типы могут включать другие

3) Если спецификации не изменились то дальше по спецификации генерируем входные значения и проверяем что результат работы старого кода на этих значениях такой же как и на новых

рассказ про рефакторинг сторов
---
# Refinement типы

Следующая клевая штука которую очень хотелось бы иметь в арсенале средств доказательств - это рефайнемент типы

Опять таки как мы помним в мире доказательств все дуально
Начнем с динамического варианта - тут все просто - любой динамический тип это функция валидатор - так вот рефанемент это просто некий кастомный валидатор. Объявить его легко. А вот проверить не так уж просто
Если для предопределенных валидаторов мы можем заранее написать генераторы то для каждого нового кастомного валидатора нам придется каждый раз писать свой генератор - возникает вопрос а можем ли мы это автоматизировать?
То есть как сгенерировать данные по некотрому кастомному валидатору?
Существует интересный пейпер в котором строится специальный язык в котором каждый валидатор(предикат) автоматически является генератором - это достигается путем комбинации некотрых техник
(таких как контр примеры и смт солвинг)


В статическом варианте так же стоит вопрос как доказывать подобные утверждения - ответ также стоит искать в пейперах - по ликвид хаскелю и рефайнемент тайпскрипту.

SMT (satisfiability modulo theories)  solving - смт солвер это инструмент который позволяет доказать вычислимость некотрой формулы в рамках конкретной теории - да я тоже ничего не понимаю. В сети не так уж много инфы о том что это такое и как это применяется на практике. Однако тема очень важная - кроме типов она также используется в системах лейаутинга - например на айоси. Для жс есть порт Cassowary и GridSS - специальное расширение для ксс. Если кому интересно как сделать хорошую систему гридов - тоже рекомендую изучать тему
---
# Перерыв
---
# ~~Type~~ Spec Driven Development
А теперь попробуем Top-Down подход
Давайте попробуем расмотреть типичную таску в трелло
расказываю что в таске
---
# А что мы хотим получить?
Давайте составим
а) общую спецификацию  - естественно мы сделаем это ввиде типов
Используем маппинг тип - в котором вход сопоставляется выходу

б) также отдельные кейсы

собственно теперь нам осталось начать писать код который будет соотвествывать жтим спекам

А что если не писать код? как договорится если долго сидеть на берегу реки то можно увидеть проплывающий труп врага - так может код сам напишется?
---
# Как найти то - не знаю что
Ну вообще давайте вспомним тот простой факт что не одна программа не пишется с нуля
У нас всегда уже есть очень много кода
а) стд либ
б) сторронниие либы
в) и обычно проект уже есть и там есть какой то код - утилиты компоненты и так далее

Можем ли мы имея некотроее формальное описание требований(в виде тестов или типов) к коду найти решение которое подходит под это описание?

Да можем! например проект хугл для хаскеля позволяет по типу функции найти функцию с подобным типом

Или к примеру проект рембо для библиотеки рамда - позволяет по варианту входа и выхода(тест кейзу) найти комбинацию функций в рамде

то есть в одном случае используются типы а в другом тесты - давайте попробуем собрать эти решения в кучу
---
# Синтез подходов
1) Разбиваем отображения типов на мельчайшие части каким то образом
Пример
то есть разбиваем один маппинг на множество маппингов - все возможные варианты

2) Ищем по соответсвиям спецификациям по проекту и подключенным либам

3) проделываем обратную операцию из кусочков реализации собираем возможную реализацию

4) Проверяем по тестам - если не ок, то на шаг 1

5) Прикручиваем machine learning

6) ???

7) PROFIT
---
# План увольнения большинства программистов
Чтобы этого добиться правильного ответа - правильно написанной программы, надо сначала научится задавать вопросы - то есть научится описывать требования к нашей программе в такой форме чтобы их можно было автоматически проверять - то есть доказательства того что эти требования соблюдаются.

1) Динамические доказательства

- доработка `runtypes-generate`, `io-ts-generate` - там много проблем и многое можно доделать для удобства использования
- генерация данных по предикату(Refinement типы) - ищучать смт солвинг и сделать реализацию для существующего языка(возможно придется использовать кодогенерацию)

2) Статические доказательства

- Refinement в мейнстриме(TypeScript)
- также необходимо прояснить соотношение Refinement, Dependant типов и логики Хоара(это еще один способ статически проверять свойства программы и верифицировать ее и он схож с рефайнемент)

---
# План увольнения большинства программистов
3) Доламываем стену между динамическими и статическими свойствами:

 - доработка библиотек в плане конвертации динамических типов в статические
 - также доработать сам тайпскрипт чтоб он лучше позволял это делать(например отсутсвие типов переменной длины не позволяет нормально сделать тип функции)

5) Bottom-Up
 - трейсинг вызовов сущностей(например для React компонентов в сторибуке)
 - генерация тестов по трейсингу
 - вывод типов по трейсингу

6) Top-Down
 - поиск по спецификациям по проекту или NPM с валидацией по тестам - аналог Hoogle для TypeScript
 - AI
---
# Истина не познается, а сделывается

Все мы стремимся к познанию истины - но зачастую мы связываем процесс познания только с наблюдением и ищзучением
Однако наблюдение мало - истина не лежит на поверхности - чтобы ее увидеть необходимо своей практической деятельностью вскрыть реальность
Без развития языков программирования и тулов(систем типизации бибилиотек для проперти тестов) мы бы не могли увидеть общую картину так хорошо как мы видим ее сейчас - но впереди еще много работы и необходимо дальше усовершенствовать работу с доказательствами чтобы лучше увидеть взаимосвязи отдельных явлений в этой области





Первым примером этой тактики будет служить пресловутая иммутабельность - подход к работе с данными при котором никакие данные нельзя менять напрямую - позволяется только создавать новые данные на основе старых - то есть к примеру мы не удаляем ключ из обьекта а создаем новый обьект который содержит все ключи старго кроме того который хотели удалить.
Давайте посмотрим пример мутабельного и не мутабельного изменения в нашем коде
Можем ли мы в первом случае как то понять было ли произведено изменение и что конкретно изменилось?
Мы не можем сказать об этом ни по коду ни в рантайме - после выполенния changeObj у нас будет только измененое a которое мы не с можем ни с чем сравнить и увидеть чтоже там изменилось

Во втором случае мы точно видим по коду что функция changeObj "меняет" исходный обьект и более того в рантайме мы можем сранивать aChanged и a и понять что конкретно изменилось в результате работы функции.

Пример по сложнее

Как мы уже выясняли внешний мир постоянно меняется - а наш код очень часто работает с внешним миром.
Давайте возьмем такое постоянно изменяющее свойство внешнего мира как время - как мы можем работать с ним в коде?
Предположим мы хотим иногда получать текущее время + 5 секунд.
В первом случае мы будем всегда получать текущее время и просто прибавлять к нему 5 секунд

Во втором случае мы представим время как некотрую последовательность - как будто это бесконечный массив элементы которого постоянно прибывают - затем отобразим эту последовательность используя мап - точно также как мы это делаем для массивов
И затем подпишемся на него с интервалом в одну милисекунду.

Во втором случае любое изменение времени будет явным и наблюдаемым - мы можем подписатся и как то реагировать на его изменения. В первом же случае в коде нам придется постоянно проверять, а не изменилось ли время - если мы хотим к примеру как то реагировать на эти изменения.

Эта техника представления изменяющихся с течением времени значений получила названия Functional Reactive Programming в и вдохновила многие инструменты - такие как редакс, rxjs, и многих другие